{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Edit Networks\n",
    "\n",
    "This notebook contains applications of graph edit networks (without edge actions) to trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Boolean Formula Simplification\n",
    "\n",
    "We generate a random Boolean formula over the variables $x$ and $y$ with at most 3 binary operators and then apply simplification rules until none apply anymore. The time series is the series of iteratively simpler formulae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the model\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_tree_edit_networks as ten\n",
    "\n",
    "# the number of experimental repititions\n",
    "R = 5\n",
    "# the number of test trees\n",
    "N_test = 10\n",
    "\n",
    "# training hyperparameters\n",
    "max_epochs     = 30000\n",
    "learning_rate  = 1E-3\n",
    "weight_decay   = 1E-5\n",
    "loss_threshold = 1E-3\n",
    "\n",
    "# model hyperparameters\n",
    "num_layers = 2\n",
    "dim_hid = 64\n",
    "skip_connections = False\n",
    "nonlin = torch.nn.ReLU()\n",
    "max_degree = 4\n",
    "\n",
    "accs = np.zeros(R)\n",
    "learning_curves = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- repeat 1 of 5 ---\n"
     ]
    }
   ],
   "source": [
    "# learn\n",
    "import edist.tree_utils as tu\n",
    "import boolean_formulae\n",
    "\n",
    "unique = True\n",
    "\n",
    "for r in range(R):\n",
    "    print('--- repeat %d of %d ---' % (r+1, R))\n",
    "    test_set, unique_As = boolean_formulae.create_test_set(N_test)\n",
    "    # instantiate network and optimizer\n",
    "    net = ten.TEN(num_layers = num_layers, alphabet = boolean_formulae.alphabet,\n",
    "                  dim_hid = dim_hid, skip_connections = skip_connections, nonlin = nonlin,\n",
    "                  dim_in_extra = max_degree + 1)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    # start training\n",
    "    loss_avg = None\n",
    "    learning_curve = []\n",
    "    epochs = 0\n",
    "    while epochs < max_epochs:\n",
    "        optimizer.zero_grad()\n",
    "        # sample a nontrivial time series\n",
    "        if unique:\n",
    "            time_series = boolean_formulae.generate_unique_time_series(test_set)\n",
    "        else:\n",
    "            time_series = boolean_formulae.generate_time_series()\n",
    "        if len(time_series) < 2:\n",
    "            continue\n",
    "        # compute the prediction loss\n",
    "        loss = boolean_formulae.compute_loss(net, time_series)\n",
    "        # compute the gradient\n",
    "        loss.backward()\n",
    "        # perform an optimizer step\n",
    "        optimizer.step()\n",
    "        # compute a new moving average over the loss\n",
    "        if loss_avg is None:\n",
    "            loss_avg = loss.item()\n",
    "        else:\n",
    "            loss_avg = loss_avg * 0.9 + 0.1 * loss.item()\n",
    "        learning_curve.append(loss.item())\n",
    "        if((epochs+1) % 100 == 0):\n",
    "            print('loss avg after %d epochs: %g' % (epochs+1, loss_avg))\n",
    "        epochs += 1\n",
    "        if loss_avg < loss_threshold:\n",
    "            break\n",
    "    learning_curves.append(learning_curve)\n",
    "    # after training is completed, evaluate\n",
    "    j = 0\n",
    "    T = 0\n",
    "    while j < N_test:\n",
    "        # sample a random time series\n",
    "        if unique:\n",
    "            time_series = test_set[j]\n",
    "        else:\n",
    "            time_series = boolean_formulae.generate_time_series()\n",
    "        if len(time_series) < 2:\n",
    "            continue\n",
    "        # iterate over the time series\n",
    "        for t in range(len(time_series)-1):\n",
    "            # perform the prediction\n",
    "            nodes, adj = time_series[t]\n",
    "            try:\n",
    "                _, nodes_actual, adj_actual = boolean_formulae.predict_step(net, nodes, adj)\n",
    "                nodes_expected, adj_expected = time_series[t+1]\n",
    "                if nodes_actual == nodes_expected and adj_actual == adj_expected:\n",
    "                    accs[r] += 1\n",
    "                else:\n",
    "                    print('expected tree %s but was actually %s' % (tu.tree_to_string(nodes_expected, adj_expected), tu.tree_to_string(nodes_actual, adj_actual)))\n",
    "            except Exception as ex:\n",
    "                try:\n",
    "                    boolean_formulae.predict_step(net, nodes, adj, verbose = True)\n",
    "                except Exception as ex2:\n",
    "                    pass\n",
    "                print('Exception for input tree %s and network output %s\\nexception was %s' % (tu.tree_to_string(nodes, adj, indent = True, with_indices = True), deltaX, str(ex)))\n",
    "        T += len(time_series)-1\n",
    "        j += 1\n",
    "    accs[r] /= T\n",
    "    print('accuracy: %g' % accs[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "print('Accuracy: %g +- %g' % (np.mean(accs), np.std(accs)))\n",
    "num_epochs = np.array(list(map(len, learning_curves)))\n",
    "print('Epochs: %g +- %g' % (np.mean(num_epochs), np.std(num_epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize learning curves\n",
    "import matplotlib.pyplot as plt\n",
    "smoothing_steps = 10\n",
    "for r in range(R):\n",
    "    # compute a moving average before visualization\n",
    "    acum = np.cumsum(learning_curves[r])\n",
    "    plt.semilogy((acum[smoothing_steps:] - acum[:-smoothing_steps])/smoothing_steps)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Addition\n",
    "\n",
    "We generate an addition formula of at most four numbers in the range 1-3 and then use the Peano addition axiom to compute the addition. In particular, the following four rules apply.\n",
    "\n",
    "1. +(m, 0) for any m can be replaced with m.\n",
    "2. +(m, succ(n)) can be replaced with succ(+(m, n)).\n",
    "3. +(m, n) for n in the range 0-9 can be replaced with +(m, succ(n-1)) where -1 refers to the numeric subtraction of 1.\n",
    "4. succ(n) for n in the range 0-9 can be replaced with n+1 (mod 10 because we don't permit two-digit numbers).\n",
    "\n",
    "A time series arises by applying to a current tree every rule that is applicable until a tree results which is only a single number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the model\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_tree_edit_networks as ten\n",
    "\n",
    "# the number of experimental repititions\n",
    "R = 5\n",
    "# the number of test trees\n",
    "N_test = 10\n",
    "\n",
    "# training hyperparameters\n",
    "max_epochs     = 30000\n",
    "learning_rate  = 1E-3\n",
    "weight_decay   = 1E-5\n",
    "loss_threshold = 1E-3\n",
    "\n",
    "# model hyperparameters\n",
    "# a single layer with sufficient neurons should suffice here, because we only need to\n",
    "# check immediate parents and children to check whether a rule applies\n",
    "num_layers = 2\n",
    "dim_hid = 64\n",
    "skip_connections = False\n",
    "nonlin = torch.nn.ReLU()\n",
    "max_degree = 2\n",
    "\n",
    "accs = np.zeros(R)\n",
    "learning_curves = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- repeat 1 of 5 ---\n",
      "loss avg after 100 epochs: 412.88\n",
      "loss avg after 200 epochs: 188.633\n",
      "loss avg after 300 epochs: 108.75\n",
      "loss avg after 400 epochs: 83.5314\n",
      "loss avg after 500 epochs: 39.0241\n",
      "loss avg after 600 epochs: 28.1514\n",
      "loss avg after 700 epochs: 35.2105\n",
      "loss avg after 800 epochs: 15.8604\n",
      "loss avg after 900 epochs: 13.0377\n",
      "loss avg after 1000 epochs: 7.27475\n",
      "loss avg after 1100 epochs: 7.44812\n",
      "loss avg after 1200 epochs: 3.56508\n",
      "loss avg after 1300 epochs: 2.90106\n",
      "loss avg after 1400 epochs: 2.30318\n",
      "loss avg after 1500 epochs: 1.77996\n",
      "loss avg after 1600 epochs: 1.60777\n",
      "loss avg after 1700 epochs: 1.69116\n",
      "loss avg after 1800 epochs: 1.51791\n",
      "loss avg after 1900 epochs: 1.08536\n",
      "loss avg after 2000 epochs: 1.07082\n",
      "loss avg after 2100 epochs: 0.897198\n",
      "loss avg after 2200 epochs: 0.626463\n",
      "loss avg after 2300 epochs: 0.485799\n",
      "loss avg after 2400 epochs: 0.471478\n",
      "loss avg after 2500 epochs: 0.611787\n",
      "loss avg after 2600 epochs: 0.468785\n",
      "loss avg after 2700 epochs: 0.379\n",
      "loss avg after 2800 epochs: 0.527805\n",
      "loss avg after 2900 epochs: 5.23085\n",
      "loss avg after 3000 epochs: 0.530921\n",
      "loss avg after 3100 epochs: 0.406706\n",
      "loss avg after 3200 epochs: 0.329081\n",
      "loss avg after 3300 epochs: 0.260822\n",
      "loss avg after 3400 epochs: 0.226553\n",
      "loss avg after 3500 epochs: 0.184178\n",
      "loss avg after 3600 epochs: 0.1926\n",
      "loss avg after 3700 epochs: 0.135163\n",
      "loss avg after 3800 epochs: 0.151504\n",
      "loss avg after 3900 epochs: 0.178802\n",
      "loss avg after 4000 epochs: 0.104935\n",
      "loss avg after 4100 epochs: 0.110547\n",
      "loss avg after 4200 epochs: 0.102749\n",
      "loss avg after 4300 epochs: 0.099885\n",
      "loss avg after 4400 epochs: 0.0923101\n",
      "loss avg after 4500 epochs: 0.0936849\n",
      "loss avg after 4600 epochs: 0.144949\n",
      "loss avg after 4700 epochs: 0.11891\n",
      "loss avg after 4800 epochs: 0.0705811\n",
      "loss avg after 4900 epochs: 0.0627021\n",
      "loss avg after 5000 epochs: 0.060002\n",
      "loss avg after 5100 epochs: 0.0478377\n",
      "loss avg after 5200 epochs: 0.0466103\n",
      "loss avg after 5300 epochs: 0.0473712\n",
      "loss avg after 5400 epochs: 0.0396234\n",
      "loss avg after 5500 epochs: 0.0498376\n",
      "loss avg after 5600 epochs: 0.262294\n",
      "loss avg after 5700 epochs: 0.0478006\n",
      "loss avg after 5800 epochs: 0.0467791\n",
      "loss avg after 5900 epochs: 0.039324\n",
      "loss avg after 6000 epochs: 0.0655487\n",
      "loss avg after 6100 epochs: 0.0376201\n",
      "loss avg after 6200 epochs: 0.0235395\n",
      "loss avg after 6300 epochs: 0.0283559\n",
      "loss avg after 6400 epochs: 0.0226084\n",
      "loss avg after 6500 epochs: 0.0210969\n",
      "loss avg after 6600 epochs: 0.0187365\n",
      "loss avg after 6700 epochs: 0.031763\n",
      "loss avg after 6800 epochs: 0.0271502\n",
      "loss avg after 6900 epochs: 0.0123821\n",
      "loss avg after 7000 epochs: 0.0122766\n",
      "loss avg after 7100 epochs: 0.0156882\n",
      "loss avg after 7200 epochs: 0.0122973\n",
      "loss avg after 7300 epochs: 0.0105996\n",
      "loss avg after 7400 epochs: 0.0116457\n",
      "loss avg after 7500 epochs: 0.0140666\n",
      "loss avg after 7600 epochs: 0.00886211\n",
      "loss avg after 7700 epochs: 0.103019\n",
      "loss avg after 7800 epochs: 0.0202482\n",
      "loss avg after 7900 epochs: 0.0434321\n",
      "loss avg after 8000 epochs: 0.0499878\n",
      "loss avg after 8100 epochs: 0.0256972\n",
      "loss avg after 8200 epochs: 0.0163156\n",
      "loss avg after 8300 epochs: 0.0120343\n",
      "loss avg after 8400 epochs: 0.0126455\n",
      "loss avg after 8500 epochs: 0.0087847\n",
      "loss avg after 8600 epochs: 0.00958538\n",
      "loss avg after 8700 epochs: 0.00709604\n",
      "loss avg after 8800 epochs: 0.00741386\n",
      "loss avg after 8900 epochs: 0.00583881\n",
      "loss avg after 9000 epochs: 0.00646968\n",
      "loss avg after 9100 epochs: 0.318924\n",
      "loss avg after 9200 epochs: 0.103639\n",
      "loss avg after 9300 epochs: 0.0488021\n",
      "loss avg after 9400 epochs: 0.0166474\n",
      "loss avg after 9500 epochs: 0.0152369\n",
      "loss avg after 9600 epochs: 0.00822112\n",
      "loss avg after 9700 epochs: 0.00886673\n",
      "loss avg after 9800 epochs: 0.00615617\n",
      "loss avg after 9900 epochs: 0.0056508\n",
      "loss avg after 10000 epochs: 0.00479412\n",
      "loss avg after 10100 epochs: 0.00350782\n",
      "loss avg after 10200 epochs: 0.00396492\n",
      "loss avg after 10300 epochs: 0.00416782\n",
      "loss avg after 10400 epochs: 0.00359478\n",
      "loss avg after 10500 epochs: 0.00287283\n",
      "loss avg after 10600 epochs: 0.00287358\n",
      "loss avg after 10700 epochs: 0.00233028\n",
      "loss avg after 10800 epochs: 0.00300293\n",
      "loss avg after 10900 epochs: 0.0022986\n",
      "loss avg after 11000 epochs: 0.00224836\n",
      "loss avg after 11100 epochs: 0.00162066\n",
      "loss avg after 11200 epochs: 0.00317364\n",
      "loss avg after 11300 epochs: 0.00180454\n",
      "loss avg after 11400 epochs: 0.00164786\n",
      "loss avg after 11500 epochs: 0.00201696\n",
      "loss avg after 11600 epochs: 0.0015775\n",
      "loss avg after 11700 epochs: 0.00155404\n",
      "loss avg after 11800 epochs: 0.00133247\n",
      "accuracy: 1\n",
      "--- repeat 2 of 5 ---\n",
      "loss avg after 100 epochs: 306.59\n",
      "loss avg after 200 epochs: 194.287\n",
      "loss avg after 300 epochs: 126.829\n",
      "loss avg after 400 epochs: 106.359\n",
      "loss avg after 500 epochs: 73.0527\n",
      "loss avg after 600 epochs: 55.6027\n",
      "loss avg after 700 epochs: 42.536\n",
      "loss avg after 800 epochs: 29.6066\n",
      "loss avg after 900 epochs: 18.7561\n",
      "loss avg after 1000 epochs: 11.7081\n",
      "loss avg after 1100 epochs: 8.59693\n",
      "loss avg after 1200 epochs: 6.31473\n",
      "loss avg after 1300 epochs: 3.71565\n",
      "loss avg after 1400 epochs: 3.66523\n",
      "loss avg after 1500 epochs: 2.47002\n",
      "loss avg after 1600 epochs: 1.88251\n",
      "loss avg after 1700 epochs: 1.57493\n",
      "loss avg after 1800 epochs: 1.28861\n",
      "loss avg after 1900 epochs: 1.13581\n",
      "loss avg after 2000 epochs: 0.971084\n",
      "loss avg after 2100 epochs: 1.0272\n",
      "loss avg after 2200 epochs: 0.605453\n",
      "loss avg after 2300 epochs: 0.594657\n",
      "loss avg after 2400 epochs: 0.499224\n",
      "loss avg after 2500 epochs: 0.702599\n",
      "loss avg after 2600 epochs: 0.439641\n",
      "loss avg after 2700 epochs: 0.400165\n",
      "loss avg after 2800 epochs: 0.3214\n",
      "loss avg after 2900 epochs: 0.275167\n",
      "loss avg after 3000 epochs: 0.334623\n",
      "loss avg after 3100 epochs: 0.301521\n",
      "loss avg after 3200 epochs: 0.244919\n",
      "loss avg after 3300 epochs: 0.154518\n",
      "loss avg after 3400 epochs: 0.175046\n",
      "loss avg after 3500 epochs: 0.138121\n",
      "loss avg after 3600 epochs: 1.82087\n",
      "loss avg after 3700 epochs: 0.420962\n",
      "loss avg after 3800 epochs: 0.268338\n",
      "loss avg after 3900 epochs: 0.292654\n",
      "loss avg after 4000 epochs: 0.1997\n",
      "loss avg after 4100 epochs: 0.146497\n",
      "loss avg after 4200 epochs: 0.171923\n",
      "loss avg after 4300 epochs: 0.159382\n",
      "loss avg after 4400 epochs: 0.137519\n",
      "loss avg after 4500 epochs: 0.10121\n",
      "loss avg after 4600 epochs: 0.109573\n",
      "loss avg after 4700 epochs: 0.0914864\n",
      "loss avg after 4800 epochs: 0.0781399\n",
      "loss avg after 4900 epochs: 0.113595\n",
      "loss avg after 5000 epochs: 0.0591917\n",
      "loss avg after 5100 epochs: 0.0612883\n",
      "loss avg after 5200 epochs: 0.0544855\n",
      "loss avg after 5300 epochs: 0.0537674\n",
      "loss avg after 5400 epochs: 0.0493129\n",
      "loss avg after 5500 epochs: 0.0491209\n",
      "loss avg after 5600 epochs: 0.0522934\n",
      "loss avg after 5700 epochs: 0.0368549\n",
      "loss avg after 5800 epochs: 0.0530985\n",
      "loss avg after 5900 epochs: 0.0291767\n",
      "loss avg after 6000 epochs: 0.0270458\n",
      "loss avg after 6100 epochs: 0.0195577\n",
      "loss avg after 6200 epochs: 0.0341961\n",
      "loss avg after 6300 epochs: 0.0216746\n",
      "loss avg after 6400 epochs: 0.0580692\n",
      "loss avg after 6500 epochs: 0.0434982\n",
      "loss avg after 6600 epochs: 0.0284904\n",
      "loss avg after 6700 epochs: 0.0281213\n",
      "loss avg after 6800 epochs: 0.0263801\n",
      "loss avg after 6900 epochs: 0.0244184\n",
      "loss avg after 7000 epochs: 0.020464\n",
      "loss avg after 7100 epochs: 0.0151405\n",
      "loss avg after 7200 epochs: 0.0170975\n",
      "loss avg after 7300 epochs: 0.0215934\n",
      "loss avg after 7400 epochs: 0.0118934\n",
      "loss avg after 7500 epochs: 0.0124208\n",
      "loss avg after 7600 epochs: 0.0108852\n",
      "loss avg after 7700 epochs: 0.0138137\n",
      "loss avg after 7800 epochs: 0.0138418\n",
      "loss avg after 7900 epochs: 0.00983968\n",
      "loss avg after 8000 epochs: 0.0117861\n",
      "loss avg after 8100 epochs: 0.0114887\n",
      "loss avg after 8200 epochs: 0.00811474\n",
      "loss avg after 8300 epochs: 0.00687795\n",
      "loss avg after 8400 epochs: 0.00705652\n",
      "loss avg after 8500 epochs: 0.00549054\n",
      "loss avg after 8600 epochs: 0.00756613\n",
      "loss avg after 8700 epochs: 0.00476697\n",
      "loss avg after 8800 epochs: 0.00724469\n",
      "loss avg after 8900 epochs: 0.00728897\n",
      "loss avg after 9000 epochs: 0.00413122\n",
      "loss avg after 9100 epochs: 0.00492206\n",
      "loss avg after 9200 epochs: 0.00580947\n",
      "loss avg after 9300 epochs: 0.00460092\n",
      "loss avg after 9400 epochs: 0.00304594\n",
      "loss avg after 9500 epochs: 0.0044775\n",
      "loss avg after 9600 epochs: 0.00368678\n",
      "loss avg after 9700 epochs: 0.00461678\n",
      "loss avg after 9800 epochs: 0.00368918\n",
      "loss avg after 9900 epochs: 0.00427637\n",
      "loss avg after 10000 epochs: 0.00641755\n",
      "loss avg after 10100 epochs: 0.00304314\n",
      "loss avg after 10200 epochs: 0.00254328\n",
      "loss avg after 10300 epochs: 0.00319448\n",
      "loss avg after 10400 epochs: 0.00743212\n",
      "loss avg after 10500 epochs: 0.89663\n",
      "loss avg after 10600 epochs: 0.116096\n",
      "loss avg after 10700 epochs: 0.0458062\n",
      "loss avg after 10800 epochs: 0.0319004\n",
      "loss avg after 10900 epochs: 0.0272386\n",
      "loss avg after 11000 epochs: 0.0202005\n",
      "loss avg after 11100 epochs: 0.015735\n",
      "loss avg after 11200 epochs: 0.0137749\n",
      "loss avg after 11300 epochs: 0.0103377\n",
      "loss avg after 11400 epochs: 0.0133205\n",
      "loss avg after 11500 epochs: 0.0113656\n",
      "loss avg after 11600 epochs: 0.00813533\n",
      "loss avg after 11700 epochs: 0.00703814\n",
      "loss avg after 11800 epochs: 0.00687856\n",
      "loss avg after 11900 epochs: 0.00581565\n",
      "loss avg after 12000 epochs: 0.00722786\n",
      "loss avg after 12100 epochs: 0.00586422\n",
      "loss avg after 12200 epochs: 0.00578525\n",
      "loss avg after 12300 epochs: 0.00514659\n",
      "loss avg after 12400 epochs: 0.00450083\n",
      "loss avg after 12500 epochs: 0.00362492\n",
      "loss avg after 12600 epochs: 0.00381286\n",
      "loss avg after 12700 epochs: 0.00327498\n",
      "loss avg after 12800 epochs: 0.0032137\n",
      "loss avg after 12900 epochs: 0.00301647\n",
      "loss avg after 13000 epochs: 0.00298473\n",
      "loss avg after 13100 epochs: 0.00244536\n",
      "loss avg after 13200 epochs: 0.00308008\n",
      "loss avg after 13300 epochs: 0.00271133\n",
      "loss avg after 13400 epochs: 0.00187347\n",
      "loss avg after 13500 epochs: 0.0022709\n",
      "loss avg after 13600 epochs: 0.00200167\n",
      "loss avg after 13700 epochs: 0.00160994\n",
      "loss avg after 13800 epochs: 0.00115943\n",
      "loss avg after 13900 epochs: 0.00170608\n",
      "loss avg after 14000 epochs: 0.00190207\n",
      "loss avg after 14100 epochs: 0.00118264\n",
      "loss avg after 14200 epochs: 0.00131873\n",
      "accuracy: 1\n",
      "--- repeat 3 of 5 ---\n",
      "loss avg after 100 epochs: 307.992\n",
      "loss avg after 200 epochs: 225.896\n",
      "loss avg after 300 epochs: 105.92\n",
      "loss avg after 400 epochs: 82.7527\n",
      "loss avg after 500 epochs: 67.815\n",
      "loss avg after 600 epochs: 43.624\n",
      "loss avg after 700 epochs: 19.4149\n",
      "loss avg after 800 epochs: 13.5625\n",
      "loss avg after 900 epochs: 8.792\n",
      "loss avg after 1000 epochs: 7.47581\n",
      "loss avg after 1100 epochs: 4.14373\n",
      "loss avg after 1200 epochs: 3.34771\n",
      "loss avg after 1300 epochs: 2.0407\n",
      "loss avg after 1400 epochs: 1.76571\n",
      "loss avg after 1500 epochs: 1.59492\n",
      "loss avg after 1600 epochs: 1.33564\n",
      "loss avg after 1700 epochs: 1.05972\n",
      "loss avg after 1800 epochs: 0.797376\n",
      "loss avg after 1900 epochs: 0.755887\n",
      "loss avg after 2000 epochs: 0.432746\n",
      "loss avg after 2100 epochs: 0.519732\n",
      "loss avg after 2200 epochs: 10.1849\n",
      "loss avg after 2300 epochs: 0.562655\n",
      "loss avg after 2400 epochs: 0.583056\n",
      "loss avg after 2500 epochs: 0.355322\n",
      "loss avg after 2600 epochs: 0.295993\n",
      "loss avg after 2700 epochs: 0.280805\n",
      "loss avg after 2800 epochs: 0.240073\n",
      "loss avg after 2900 epochs: 0.215042\n",
      "loss avg after 3000 epochs: 0.176981\n",
      "loss avg after 3100 epochs: 0.167239\n",
      "loss avg after 3200 epochs: 0.134042\n",
      "loss avg after 3300 epochs: 0.141168\n",
      "loss avg after 3400 epochs: 0.0973034\n",
      "loss avg after 3500 epochs: 0.103043\n",
      "loss avg after 3600 epochs: 0.113277\n",
      "loss avg after 3700 epochs: 0.0936941\n",
      "loss avg after 3800 epochs: 0.0909402\n",
      "loss avg after 3900 epochs: 0.0652128\n",
      "loss avg after 4000 epochs: 0.0729462\n",
      "loss avg after 4100 epochs: 0.0696905\n",
      "loss avg after 4200 epochs: 0.0662879\n",
      "loss avg after 4300 epochs: 0.077898\n",
      "loss avg after 4400 epochs: 1.21335\n",
      "loss avg after 4500 epochs: 0.108664\n",
      "loss avg after 4600 epochs: 0.155302\n",
      "loss avg after 4700 epochs: 0.069796\n",
      "loss avg after 4800 epochs: 0.0565884\n",
      "loss avg after 4900 epochs: 0.245284\n",
      "loss avg after 5000 epochs: 0.337938\n",
      "loss avg after 5100 epochs: 0.103555\n",
      "loss avg after 5200 epochs: 0.104329\n",
      "loss avg after 5300 epochs: 0.0803449\n",
      "loss avg after 5400 epochs: 0.0507251\n",
      "loss avg after 5500 epochs: 0.0411673\n",
      "loss avg after 5600 epochs: 0.0298195\n",
      "loss avg after 5700 epochs: 0.029751\n",
      "loss avg after 5800 epochs: 0.0229403\n",
      "loss avg after 5900 epochs: 0.0278198\n",
      "loss avg after 6000 epochs: 0.0279557\n",
      "loss avg after 6100 epochs: 0.0210471\n",
      "loss avg after 6200 epochs: 0.0204519\n",
      "loss avg after 6300 epochs: 0.0294071\n",
      "loss avg after 6400 epochs: 0.0122731\n",
      "loss avg after 6500 epochs: 0.0276985\n",
      "loss avg after 6600 epochs: 0.0179792\n",
      "loss avg after 6700 epochs: 0.0117351\n",
      "loss avg after 6800 epochs: 0.0130694\n",
      "loss avg after 6900 epochs: 0.013003\n",
      "loss avg after 7000 epochs: 0.0486947\n",
      "loss avg after 7100 epochs: 0.0126524\n",
      "loss avg after 7200 epochs: 0.00979478\n",
      "loss avg after 7300 epochs: 0.00970934\n",
      "loss avg after 7400 epochs: 0.0108935\n",
      "loss avg after 7500 epochs: 0.0081542\n",
      "loss avg after 7600 epochs: 0.00615725\n",
      "loss avg after 7700 epochs: 0.00919059\n",
      "loss avg after 7800 epochs: 0.00549737\n",
      "loss avg after 7900 epochs: 0.00894169\n",
      "loss avg after 8000 epochs: 0.00617146\n",
      "loss avg after 8100 epochs: 0.00612411\n",
      "loss avg after 8200 epochs: 0.00558515\n",
      "loss avg after 8300 epochs: 0.00422449\n",
      "loss avg after 8400 epochs: 0.00365082\n",
      "loss avg after 8500 epochs: 0.00405952\n",
      "loss avg after 8600 epochs: 0.00720109\n",
      "loss avg after 8700 epochs: 0.00795822\n",
      "loss avg after 8800 epochs: 10.4098\n",
      "loss avg after 8900 epochs: 0.11055\n",
      "loss avg after 9000 epochs: 0.0372839\n",
      "loss avg after 9100 epochs: 0.0184548\n",
      "loss avg after 9200 epochs: 0.0136122\n",
      "loss avg after 9300 epochs: 0.0133214\n",
      "loss avg after 9400 epochs: 0.0129294\n",
      "loss avg after 9500 epochs: 0.0089885\n",
      "loss avg after 9600 epochs: 0.0134619\n",
      "loss avg after 9700 epochs: 0.00806155\n",
      "loss avg after 9800 epochs: 0.00711267\n",
      "loss avg after 9900 epochs: 0.00521945\n",
      "loss avg after 10000 epochs: 0.00671276\n",
      "loss avg after 10100 epochs: 0.005224\n",
      "loss avg after 10200 epochs: 0.00736652\n",
      "loss avg after 10300 epochs: 0.00530029\n",
      "loss avg after 10400 epochs: 0.00370421\n",
      "loss avg after 10500 epochs: 0.00353219\n",
      "loss avg after 10600 epochs: 0.00294935\n",
      "loss avg after 10700 epochs: 0.0061139\n",
      "loss avg after 10800 epochs: 0.00366204\n",
      "loss avg after 10900 epochs: 0.00255401\n",
      "loss avg after 11000 epochs: 0.00367057\n",
      "loss avg after 11100 epochs: 0.00198446\n",
      "loss avg after 11200 epochs: 0.00235707\n",
      "loss avg after 11300 epochs: 0.00158828\n",
      "loss avg after 11400 epochs: 0.00204561\n",
      "loss avg after 11500 epochs: 0.00172785\n",
      "loss avg after 11600 epochs: 0.00621426\n",
      "loss avg after 11700 epochs: 0.00268978\n",
      "accuracy: 1\n",
      "--- repeat 4 of 5 ---\n",
      "loss avg after 100 epochs: 343.381\n",
      "loss avg after 200 epochs: 215.642\n",
      "loss avg after 300 epochs: 98.5257\n",
      "loss avg after 400 epochs: 87.1797\n",
      "loss avg after 500 epochs: 78.1456\n",
      "loss avg after 600 epochs: 47\n",
      "loss avg after 700 epochs: 29.214\n",
      "loss avg after 800 epochs: 24.0121\n",
      "loss avg after 900 epochs: 11.9705\n",
      "loss avg after 1000 epochs: 7.71972\n",
      "loss avg after 1100 epochs: 5.92365\n",
      "loss avg after 1200 epochs: 4.26347\n",
      "loss avg after 1300 epochs: 3.28216\n",
      "loss avg after 1400 epochs: 2.07688\n",
      "loss avg after 1500 epochs: 1.55991\n",
      "loss avg after 1600 epochs: 1.36319\n",
      "loss avg after 1700 epochs: 1.21813\n",
      "loss avg after 1800 epochs: 1.07986\n",
      "loss avg after 1900 epochs: 0.964751\n",
      "loss avg after 2000 epochs: 0.81094\n",
      "loss avg after 2100 epochs: 0.599328\n",
      "loss avg after 2200 epochs: 0.677064\n",
      "loss avg after 2300 epochs: 0.679379\n",
      "loss avg after 2400 epochs: 0.494059\n",
      "loss avg after 2500 epochs: 0.510257\n",
      "loss avg after 2600 epochs: 0.528131\n",
      "loss avg after 2700 epochs: 0.512015\n",
      "loss avg after 2800 epochs: 1.71588\n",
      "loss avg after 2900 epochs: 0.499454\n",
      "loss avg after 3000 epochs: 0.286587\n",
      "loss avg after 3100 epochs: 0.287958\n",
      "loss avg after 3200 epochs: 0.22159\n",
      "loss avg after 3300 epochs: 0.172387\n",
      "loss avg after 3400 epochs: 0.379704\n",
      "loss avg after 3500 epochs: 0.201392\n",
      "loss avg after 3600 epochs: 0.218006\n",
      "loss avg after 3700 epochs: 0.175664\n",
      "loss avg after 3800 epochs: 0.115785\n",
      "loss avg after 3900 epochs: 0.123429\n",
      "loss avg after 4000 epochs: 7.18882\n",
      "loss avg after 4100 epochs: 1.17971\n",
      "loss avg after 4200 epochs: 0.445837\n",
      "loss avg after 4300 epochs: 0.329569\n",
      "loss avg after 4400 epochs: 0.221079\n",
      "loss avg after 4500 epochs: 0.198422\n",
      "loss avg after 4600 epochs: 0.196312\n",
      "loss avg after 4700 epochs: 0.146126\n",
      "loss avg after 4800 epochs: 0.122647\n",
      "loss avg after 4900 epochs: 0.104894\n",
      "loss avg after 5000 epochs: 0.0979064\n",
      "loss avg after 5100 epochs: 0.0994694\n",
      "loss avg after 5200 epochs: 0.335125\n",
      "loss avg after 5300 epochs: 0.0727841\n",
      "loss avg after 5400 epochs: 0.0579522\n",
      "loss avg after 5500 epochs: 0.0547573\n",
      "loss avg after 5600 epochs: 0.0457408\n",
      "loss avg after 5700 epochs: 0.0553254\n",
      "loss avg after 5800 epochs: 0.0518236\n",
      "loss avg after 5900 epochs: 0.038906\n",
      "loss avg after 6000 epochs: 0.0489734\n",
      "loss avg after 6100 epochs: 0.029511\n",
      "loss avg after 6200 epochs: 0.0356287\n",
      "loss avg after 6300 epochs: 0.0272206\n",
      "loss avg after 6400 epochs: 0.0232502\n",
      "loss avg after 6500 epochs: 0.0462862\n",
      "loss avg after 6600 epochs: 0.0268557\n",
      "loss avg after 6700 epochs: 0.0172243\n",
      "loss avg after 6800 epochs: 0.0173206\n",
      "loss avg after 6900 epochs: 0.020154\n",
      "loss avg after 7000 epochs: 0.0166904\n",
      "loss avg after 7100 epochs: 0.0135547\n",
      "loss avg after 7200 epochs: 0.0131848\n",
      "loss avg after 7300 epochs: 0.0159419\n",
      "loss avg after 7400 epochs: 0.0146038\n",
      "loss avg after 7500 epochs: 0.0146657\n",
      "loss avg after 7600 epochs: 0.0108543\n",
      "loss avg after 7700 epochs: 0.0107235\n",
      "loss avg after 7800 epochs: 0.0110762\n",
      "loss avg after 7900 epochs: 0.00946748\n",
      "loss avg after 8000 epochs: 0.0127652\n",
      "loss avg after 8100 epochs: 0.00586374\n",
      "loss avg after 8200 epochs: 0.0122813\n",
      "loss avg after 8300 epochs: 0.0057035\n",
      "loss avg after 8400 epochs: 0.00484085\n",
      "loss avg after 8500 epochs: 0.00634808\n",
      "loss avg after 8600 epochs: 0.00587581\n",
      "loss avg after 8700 epochs: 0.00624232\n",
      "loss avg after 8800 epochs: 0.00515293\n",
      "loss avg after 8900 epochs: 0.00514352\n",
      "loss avg after 9000 epochs: 0.0051046\n",
      "loss avg after 9100 epochs: 0.00534406\n",
      "loss avg after 9200 epochs: 0.00384974\n",
      "loss avg after 9300 epochs: 0.00428682\n",
      "loss avg after 9400 epochs: 0.00381719\n",
      "loss avg after 9500 epochs: 0.00443952\n",
      "loss avg after 9600 epochs: 10.593\n",
      "loss avg after 9700 epochs: 0.0809308\n",
      "loss avg after 9800 epochs: 0.045218\n",
      "loss avg after 9900 epochs: 0.0217758\n",
      "loss avg after 10000 epochs: 0.0297442\n",
      "loss avg after 10100 epochs: 0.0175848\n",
      "loss avg after 10200 epochs: 0.0134565\n",
      "loss avg after 10300 epochs: 0.0125137\n",
      "loss avg after 10400 epochs: 0.0194393\n",
      "loss avg after 10500 epochs: 0.0113458\n",
      "loss avg after 10600 epochs: 0.00903355\n",
      "loss avg after 10700 epochs: 0.00928398\n",
      "loss avg after 10800 epochs: 0.0116305\n",
      "loss avg after 10900 epochs: 0.005567\n",
      "loss avg after 11000 epochs: 0.00671104\n",
      "loss avg after 11100 epochs: 0.00600108\n",
      "loss avg after 11200 epochs: 0.00591422\n",
      "loss avg after 11300 epochs: 0.0869175\n",
      "loss avg after 11400 epochs: 0.015096\n",
      "loss avg after 11500 epochs: 0.0071896\n",
      "loss avg after 11600 epochs: 0.00914093\n",
      "loss avg after 11700 epochs: 0.0056416\n",
      "loss avg after 11800 epochs: 0.00372027\n",
      "loss avg after 11900 epochs: 0.00459193\n",
      "loss avg after 12000 epochs: 0.00405963\n",
      "loss avg after 12100 epochs: 0.00382451\n",
      "loss avg after 12200 epochs: 0.00265431\n",
      "loss avg after 12300 epochs: 0.00217775\n",
      "loss avg after 12400 epochs: 0.0028116\n",
      "loss avg after 12500 epochs: 0.00281545\n",
      "loss avg after 12600 epochs: 0.00196123\n",
      "loss avg after 12700 epochs: 0.00228443\n",
      "loss avg after 12800 epochs: 0.00178231\n",
      "loss avg after 12900 epochs: 0.00205352\n",
      "loss avg after 13000 epochs: 0.00256903\n",
      "loss avg after 13100 epochs: 0.00198655\n",
      "loss avg after 13200 epochs: 0.00166064\n",
      "loss avg after 13300 epochs: 0.00308632\n",
      "accuracy: 1\n",
      "--- repeat 5 of 5 ---\n",
      "loss avg after 100 epochs: 402.918\n",
      "loss avg after 200 epochs: 242.54\n",
      "loss avg after 300 epochs: 121.516\n",
      "loss avg after 400 epochs: 72.7671\n",
      "loss avg after 500 epochs: 49.5541\n",
      "loss avg after 600 epochs: 37.6774\n",
      "loss avg after 700 epochs: 22.9249\n",
      "loss avg after 800 epochs: 15.3667\n",
      "loss avg after 900 epochs: 8.16013\n",
      "loss avg after 1000 epochs: 5.48884\n",
      "loss avg after 1100 epochs: 4.57461\n",
      "loss avg after 1200 epochs: 3.48951\n",
      "loss avg after 1300 epochs: 2.9813\n",
      "loss avg after 1400 epochs: 2.06221\n",
      "loss avg after 1500 epochs: 2.05243\n",
      "loss avg after 1600 epochs: 1.55188\n",
      "loss avg after 1700 epochs: 1.26721\n",
      "loss avg after 1800 epochs: 3.14951\n",
      "loss avg after 1900 epochs: 4.45136\n",
      "loss avg after 2000 epochs: 2.03166\n",
      "loss avg after 2100 epochs: 1.43903\n",
      "loss avg after 2200 epochs: 1.00415\n",
      "loss avg after 2300 epochs: 0.654694\n",
      "loss avg after 2400 epochs: 0.869415\n",
      "loss avg after 2500 epochs: 0.522935\n",
      "loss avg after 2600 epochs: 0.539285\n",
      "loss avg after 2700 epochs: 0.422361\n",
      "loss avg after 2800 epochs: 0.525909\n",
      "loss avg after 2900 epochs: 0.34074\n",
      "loss avg after 3000 epochs: 0.282982\n",
      "loss avg after 3100 epochs: 0.317226\n",
      "loss avg after 3200 epochs: 0.253619\n",
      "loss avg after 3300 epochs: 0.37269\n",
      "loss avg after 3400 epochs: 0.440419\n",
      "loss avg after 3500 epochs: 0.247335\n",
      "loss avg after 3600 epochs: 0.209673\n",
      "loss avg after 3700 epochs: 0.19353\n",
      "loss avg after 3800 epochs: 0.179174\n",
      "loss avg after 3900 epochs: 0.172397\n",
      "loss avg after 4000 epochs: 0.138774\n",
      "loss avg after 4100 epochs: 0.185067\n",
      "loss avg after 4200 epochs: 0.113333\n",
      "loss avg after 4300 epochs: 0.0995501\n",
      "loss avg after 4400 epochs: 0.0836032\n",
      "loss avg after 4500 epochs: 0.0728257\n",
      "loss avg after 4600 epochs: 0.0858081\n",
      "loss avg after 4700 epochs: 0.0808157\n",
      "loss avg after 4800 epochs: 0.0697517\n",
      "loss avg after 4900 epochs: 0.0771096\n",
      "loss avg after 5000 epochs: 0.0582388\n",
      "loss avg after 5100 epochs: 0.0571821\n",
      "loss avg after 5200 epochs: 0.0743085\n",
      "loss avg after 5300 epochs: 0.0531444\n",
      "loss avg after 5400 epochs: 0.0470299\n",
      "loss avg after 5500 epochs: 0.0748859\n",
      "loss avg after 5600 epochs: 0.0479522\n",
      "loss avg after 5700 epochs: 0.0384735\n",
      "loss avg after 5800 epochs: 0.0578657\n",
      "loss avg after 5900 epochs: 0.0448238\n",
      "loss avg after 6000 epochs: 0.0430187\n",
      "loss avg after 6100 epochs: 0.0389335\n",
      "loss avg after 6200 epochs: 1.78089\n",
      "loss avg after 6300 epochs: 0.354905\n",
      "loss avg after 6400 epochs: 0.17396\n",
      "loss avg after 6500 epochs: 0.176111\n",
      "loss avg after 6600 epochs: 0.125432\n",
      "loss avg after 6700 epochs: 0.0879134\n",
      "loss avg after 6800 epochs: 0.0912296\n",
      "loss avg after 6900 epochs: 0.070152\n",
      "loss avg after 7000 epochs: 0.0404161\n",
      "loss avg after 7100 epochs: 0.045737\n",
      "loss avg after 7200 epochs: 0.0492855\n",
      "loss avg after 7300 epochs: 0.0421553\n",
      "loss avg after 7400 epochs: 0.0354056\n",
      "loss avg after 7500 epochs: 0.0317329\n",
      "loss avg after 7600 epochs: 0.0326086\n",
      "loss avg after 7700 epochs: 0.0269378\n",
      "loss avg after 7800 epochs: 0.023479\n",
      "loss avg after 7900 epochs: 0.0212517\n",
      "loss avg after 8000 epochs: 0.0223801\n",
      "loss avg after 8100 epochs: 0.0182418\n",
      "loss avg after 8200 epochs: 0.0150364\n",
      "loss avg after 8300 epochs: 0.0198367\n",
      "loss avg after 8400 epochs: 0.0133095\n",
      "loss avg after 8500 epochs: 0.0147044\n",
      "loss avg after 8600 epochs: 0.0124436\n",
      "loss avg after 8700 epochs: 0.0113854\n",
      "loss avg after 8800 epochs: 0.0140554\n",
      "loss avg after 8900 epochs: 0.0105641\n",
      "loss avg after 9000 epochs: 0.0125666\n",
      "loss avg after 9100 epochs: 0.00869003\n",
      "loss avg after 9200 epochs: 0.0107848\n",
      "loss avg after 9300 epochs: 0.0118817\n",
      "loss avg after 9400 epochs: 0.00848228\n",
      "loss avg after 9500 epochs: 0.00603964\n",
      "loss avg after 9600 epochs: 0.00538563\n",
      "loss avg after 9700 epochs: 0.00631068\n",
      "loss avg after 9800 epochs: 0.00598467\n",
      "loss avg after 9900 epochs: 0.00446347\n",
      "loss avg after 10000 epochs: 0.00436668\n",
      "loss avg after 10100 epochs: 0.0038753\n",
      "loss avg after 10200 epochs: 0.00333858\n",
      "loss avg after 10300 epochs: 0.00278764\n",
      "loss avg after 10400 epochs: 0.00310426\n",
      "loss avg after 10500 epochs: 0.0163032\n",
      "loss avg after 10600 epochs: 0.00800157\n",
      "loss avg after 10700 epochs: 0.00795342\n",
      "loss avg after 10800 epochs: 0.00464918\n",
      "loss avg after 10900 epochs: 0.00607866\n",
      "loss avg after 11000 epochs: 0.00384888\n",
      "loss avg after 11100 epochs: 0.00300451\n",
      "loss avg after 11200 epochs: 0.00473065\n",
      "loss avg after 11300 epochs: 0.00253779\n",
      "loss avg after 11400 epochs: 0.00250083\n",
      "loss avg after 11500 epochs: 0.00238383\n",
      "loss avg after 11600 epochs: 0.00336375\n",
      "loss avg after 11700 epochs: 0.00226925\n",
      "loss avg after 11800 epochs: 0.00232467\n",
      "loss avg after 11900 epochs: 0.00228975\n",
      "loss avg after 12000 epochs: 0.00255327\n",
      "loss avg after 12100 epochs: 0.00230531\n",
      "loss avg after 12200 epochs: 0.00189048\n",
      "loss avg after 12300 epochs: 0.00182686\n",
      "loss avg after 12400 epochs: 0.00138675\n",
      "loss avg after 12500 epochs: 0.00895981\n",
      "loss avg after 12600 epochs: 0.0016466\n",
      "accuracy: 1\n"
     ]
    }
   ],
   "source": [
    "# learn\n",
    "import edist.tree_utils as tu\n",
    "import peano_addition\n",
    "\n",
    "for r in range(R):\n",
    "    print('--- repeat %d of %d ---' % (r+1, R))\n",
    "    # instantiate network and optimizer\n",
    "    net = ten.TEN(num_layers = num_layers, alphabet = peano_addition.alphabet,\n",
    "                  dim_hid = dim_hid, skip_connections = skip_connections, nonlin = nonlin,\n",
    "                  dim_in_extra = max_degree + 1)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    # start training\n",
    "    loss_avg = None\n",
    "    learning_curve = []\n",
    "    epochs = 0\n",
    "    while epochs < max_epochs:\n",
    "        optimizer.zero_grad()\n",
    "        # sample a nontrivial time series\n",
    "        time_series = peano_addition.generate_time_series()\n",
    "        if len(time_series) < 2:\n",
    "            continue\n",
    "        # compute the prediction loss\n",
    "        loss = peano_addition.compute_loss(net, time_series)\n",
    "        # compute the gradient\n",
    "        loss.backward()\n",
    "        # perform an optimizer step\n",
    "        optimizer.step()\n",
    "        # compute a new moving average over the loss\n",
    "        if loss_avg is None:\n",
    "            loss_avg = loss.item()\n",
    "        else:\n",
    "            loss_avg = loss_avg * 0.9 + 0.1 * loss.item()\n",
    "        learning_curve.append(loss.item())\n",
    "        if((epochs+1) % 100 == 0):\n",
    "            print('loss avg after %d epochs: %g' % (epochs+1, loss_avg))\n",
    "        epochs += 1\n",
    "        if loss_avg < loss_threshold:\n",
    "            break\n",
    "    learning_curves.append(learning_curve)\n",
    "    # after training is completed, evaluate\n",
    "    j = 0\n",
    "    T = 0\n",
    "    while j < N_test:\n",
    "        # sample a random time series\n",
    "        time_series = peano_addition.generate_time_series()\n",
    "        if len(time_series) < 2:\n",
    "            continue\n",
    "        # iterate over the time series\n",
    "        for t in range(len(time_series)-1):\n",
    "            # perform the prediction\n",
    "            nodes, adj = time_series[t]\n",
    "            try:\n",
    "                _, nodes_actual, adj_actual = peano_addition.predict_step(net, nodes, adj)\n",
    "                nodes_expected, adj_expected = time_series[t+1]\n",
    "                if nodes_actual == nodes_expected and adj_actual == adj_expected:\n",
    "                    accs[r] += 1\n",
    "                else:\n",
    "                    print('expected tree %s but was actually %s' % (tu.tree_to_string(nodes_expected, adj_expected), tu.tree_to_string(nodes_actual, adj_actual)))\n",
    "            except Exception as ex:\n",
    "                try:\n",
    "                    peano_addition.predict_step(net, nodes, adj, verbose = True)\n",
    "                except Exception as ex2:\n",
    "                    pass\n",
    "                print('Exception for input tree %s and network output %s\\nexception was %s' % (tu.tree_to_string(nodes, adj, indent = True, with_indices = True), deltaX, str(ex)))\n",
    "        T += len(time_series)-1\n",
    "        j += 1\n",
    "    accs[r] /= T\n",
    "    print('accuracy: %g' % accs[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1 +- 0\n",
      "Epochs: 12768.4 +- 933.092\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "print('Accuracy: %g +- %g' % (np.mean(accs), np.std(accs)))\n",
    "num_epochs = np.array(list(map(len, learning_curves)))\n",
    "print('Epochs: %g +- %g' % (np.mean(num_epochs), np.std(num_epochs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize learning curves\n",
    "import matplotlib.pyplot as plt\n",
    "smoothing_steps = 10\n",
    "for r in range(R):\n",
    "    # compute a moving average before visualization\n",
    "    acum = np.cumsum(learning_curves[r])\n",
    "    plt.semilogy((acum[smoothing_steps:] - acum[:-smoothing_steps])/smoothing_steps)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
