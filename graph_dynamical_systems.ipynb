{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Dynamical Systems\n",
    "\n",
    "This notebooks contains the experiments to evaluate graph edit networks on simple graph dynamical systems, namely the edit cycles, degree rules, and game of life datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_graph_edit_networks as gen\n",
    "import baseline_models\n",
    "import hep_th\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "# model hyperparameters\n",
    "num_layers = 2\n",
    "dim_hid = 64\n",
    "\n",
    "# training hyperparameters\n",
    "learning_rate  = 1E-3\n",
    "weight_decay   = 1E-5\n",
    "loss_threshold = 1E-3\n",
    "max_epochs     = 10000\n",
    "print_step     = 1000\n",
    "\n",
    "# the number of repitions for each experiment\n",
    "R = 5\n",
    "# the number of test time series we use to evaluate learning afterwards\n",
    "N_test = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up model names\n",
    "models = ['VGAE', 'GEN_crossent', 'GEN']\n",
    "\n",
    "# set up functions to initialize the models\n",
    "def setup_vgae(dim_in, nonlin):\n",
    "    return baseline_models.VGAE(num_layers = num_layers, dim_in = dim_in, dim_hid = dim_hid, beta = 1E-3, sigma_scaling = 1E-3, nonlin = nonlin)\n",
    "def setup_gen(dim_in, nonlin):\n",
    "    return gen.GEN(num_layers = num_layers, dim_in = dim_in, dim_hid = dim_hid, nonlin = nonlin)\n",
    "setup_funs = [setup_vgae, setup_gen, setup_gen]\n",
    "# set up functions to compute the loss\n",
    "loss_fun = gen.GEN_loss()\n",
    "crossent_loss_fun = gen.GEN_loss_crossent()\n",
    "def vgae_loss(model, A, X, delta, Epsilon):\n",
    "    B = A + Epsilon\n",
    "    # delete all outgoing and incoming edges of deleted nodes\n",
    "    B[delta < -0.5, :] = 0\n",
    "    B[:, delta < -0.5] = 0\n",
    "    return model.compute_loss(torch.tensor(A, dtype=torch.float), torch.tensor(B, dtype=torch.float), torch.tensor(X, dtype=torch.float))\n",
    "def gen_loss_crossent(model, A, X, delta, Epsilon):\n",
    "    delta_pred, Epsilon_pred = model(torch.tensor(A, dtype=torch.float), torch.tensor(X, dtype=torch.float))\n",
    "    return crossent_loss_fun(delta_pred, Epsilon_pred, torch.tensor(delta, dtype=torch.float), torch.tensor(Epsilon, dtype=torch.float), torch.tensor(A, dtype=torch.float))\n",
    "def gen_loss(model, A, X, delta, Epsilon):\n",
    "    delta_pred, Epsilon_pred = model(torch.tensor(A, dtype=torch.float), torch.tensor(X, dtype=torch.float))\n",
    "    return loss_fun(delta_pred, Epsilon_pred, torch.tensor(delta, dtype=torch.float), torch.tensor(Epsilon, dtype=torch.float), torch.tensor(A, dtype=torch.float))\n",
    "loss_funs = [vgae_loss, gen_loss_crossent, gen_loss]\n",
    "# set up prediction functions\n",
    "def vgae_pred(model, A, X):\n",
    "    B = model(torch.tensor(A, dtype=torch.float), torch.tensor(X, dtype=torch.float))\n",
    "    B = B.detach().numpy()\n",
    "    Epsilon = B - A\n",
    "    delta = np.zeros(A.shape[0])\n",
    "    delta[np.sum(B, 1) < 0.5] = -1.\n",
    "    Epsilon[delta < -0.5, :] = 0.\n",
    "    Epsilon[:, delta < -0.5] = 0.\n",
    "    return delta, Epsilon\n",
    "def gen_pred(model, A, X):\n",
    "    delta_pred, Epsilon_pred = model(torch.tensor(A, dtype=torch.float), torch.tensor(X, dtype=torch.float))\n",
    "    delta_pred = delta_pred.detach().numpy()\n",
    "    Epsilon_pred = Epsilon_pred.detach().numpy()\n",
    "    delta = np.zeros(A.shape[0])\n",
    "    delta[delta_pred > 0.5] = 1.\n",
    "    delta[delta_pred < -0.5] = -1.\n",
    "    Epsilon = np.zeros(A.shape)\n",
    "    Epsilon[np.logical_and(A > 0.5, Epsilon_pred < -0.5)] = -1.\n",
    "    Epsilon[np.logical_and(A < 0.5, Epsilon_pred > +0.5)] = +1.\n",
    "    return delta, Epsilon\n",
    "pred_funs = [vgae_pred, gen_pred, gen_pred]\n",
    "\n",
    "eval_criteria = ['node_ins_recall',\n",
    "                 'node_ins_precision',\n",
    "                 'node_del_recall',\n",
    "                 'node_del_precision',\n",
    "                 'edge_ins_recall',\n",
    "                 'edge_ins_precision',\n",
    "                 'edge_del_recall',\n",
    "                 'edge_del_precision']\n",
    "# set up a function to compute precision and recall\n",
    "def prec_rec(X, Y):\n",
    "    # X is the prediction, Y is the target\n",
    "    target_insertions = Y > 0.5\n",
    "    predicted_insertions = X > 0.5\n",
    "    target_deletions = Y < -0.5\n",
    "    predicted_deletions = X < -0.5\n",
    "    # first, check the insertion recall\n",
    "    if np.sum(target_insertions) < 0.5:\n",
    "        ins_rec = 1.\n",
    "    else:\n",
    "        ins_rec  = np.mean(X[target_insertions] > 0.5)\n",
    "    # then the insertion precision\n",
    "    if np.sum(predicted_insertions) < 0.5:\n",
    "        ins_prec = 1.\n",
    "    else:\n",
    "        ins_prec = np.mean(Y[predicted_insertions] > 0.5)\n",
    "    # then the deletion recall\n",
    "    if np.sum(target_deletions) < 0.5:\n",
    "        del_rec = 1.\n",
    "    else:\n",
    "        del_rec  = np.mean(X[target_deletions] < -0.5)\n",
    "    # and finally the deletion precision\n",
    "    if np.sum(predicted_deletions) < 0.5:\n",
    "        del_prec = 1.\n",
    "    else:\n",
    "        del_prec = np.mean(Y[predicted_deletions] < -0.5)\n",
    "    return ins_rec, ins_prec, del_rec, del_prec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_edit_cycles\n",
    "import degree_rules\n",
    "import game_of_life\n",
    "import random\n",
    "\n",
    "#datasets = ['edit_cycles', 'degree_rules', 'game_of_life']\n",
    "datasets = ['edit_cycles_test100', 'degree_rules_test100', 'game_of_life_test100']\n",
    "#datasets = ['degree_rules', 'degree_rules_erdos', 'degree_rules_conf']\n",
    "dim_ins  = [4, 32, 1]\n",
    "#dim_ins  = [32, 32, 32]\n",
    "\n",
    "# set up a generative function for each data set\n",
    "def generate_edit_cycle():\n",
    "    As, Xs, tuples = graph_edit_cycles.generate_time_series(random.randrange(3), random.randrange(12), random.randrange(4, 12))\n",
    "    deltas = []\n",
    "    Epsilons = []\n",
    "    for tpl in tuples:\n",
    "        deltas.append(tpl[0])\n",
    "        Epsilons.append(tpl[1])\n",
    "    return As, Xs, deltas, Epsilons\n",
    "def generate_degree_rules():\n",
    "    # the initial number of nodes in each graph\n",
    "    n_init = 8\n",
    "    # the maximum number of nodes that can occur in each graph during evolution\n",
    "    n_max  = n_init * 4\n",
    "    return degree_rules.generate_time_series_from_random_matrix(n_init, n_max = n_max)\n",
    "\n",
    "def generate_degree_rules_erdos_renyi():\n",
    "    # the initial number of nodes in each graph\n",
    "    n_init = 8\n",
    "    # the maximum number of nodes that can occur in each graph during evolution\n",
    "    n_max  = n_init * 4\n",
    "    return degree_rules.generate_time_series_from_erdos_reny(n_init, n_max = n_max)\n",
    "\n",
    "def generate_degree_rules_configuration():\n",
    "    # the initial number of nodes in each graph\n",
    "    n_init = 8\n",
    "    # the maximum number of nodes that can occur in each graph during evolution\n",
    "    n_max  = n_init * 4\n",
    "    return degree_rules.generate_time_series_from_configuration_model(n_init, n_max = n_max)\n",
    "def generate_game_of_life():\n",
    "    # set hyper-parameters for the game of life random grid generation\n",
    "    grid_size = 10\n",
    "    num_shapes = 1\n",
    "    p = 0.1\n",
    "    T_max = 10\n",
    "    A, Xs, deltas = game_of_life.generate_random_time_series(grid_size, num_shapes, p, T_max)\n",
    "    As = [A] * len(Xs)\n",
    "    Epsilons = [np.zeros_like(A)] * len(Xs)\n",
    "    return As, Xs, deltas, Epsilons\n",
    "#generator_funs = [generate_degree_rules, generate_degree_rules_erdos_renyi, generate_degree_rules_configuration]\n",
    "generator_funs = [generate_edit_cycle, generate_degree_rules, generate_game_of_life]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- data set edit_cycles_test100 ---\n",
      "\n",
      "--- model VGAE ---\n",
      "-- repeat 1 of 5 --\n",
      "loss avg after 1000 epochs: 21.762\n",
      "loss avg after 2000 epochs: 19.823\n",
      "loss avg after 3000 epochs: 17.9872\n",
      "loss avg after 4000 epochs: 11.6172\n",
      "loss avg after 5000 epochs: 15.5081\n",
      "loss avg after 6000 epochs: 17.582\n",
      "loss avg after 7000 epochs: 19.706\n",
      "loss avg after 8000 epochs: 19.1794\n",
      "loss avg after 9000 epochs: 21.9084\n",
      "loss avg after 10000 epochs: 26.1103\n",
      "-- repeat 2 of 5 --\n",
      "loss avg after 1000 epochs: 16.9154\n",
      "loss avg after 2000 epochs: 19.0976\n",
      "loss avg after 3000 epochs: 17.619\n",
      "loss avg after 4000 epochs: 13.9539\n",
      "loss avg after 5000 epochs: 17.0943\n",
      "loss avg after 6000 epochs: 14.2292\n",
      "loss avg after 7000 epochs: 15.0716\n",
      "loss avg after 8000 epochs: 14.2374\n",
      "loss avg after 9000 epochs: 15.1168\n",
      "loss avg after 10000 epochs: 13.8677\n",
      "-- repeat 3 of 5 --\n",
      "loss avg after 1000 epochs: 27.5408\n",
      "loss avg after 2000 epochs: 31.9696\n",
      "loss avg after 3000 epochs: 20.1053\n",
      "loss avg after 4000 epochs: 15.8808\n",
      "loss avg after 5000 epochs: 16.8167\n",
      "loss avg after 6000 epochs: 14.1022\n",
      "loss avg after 7000 epochs: 15.6283\n",
      "loss avg after 8000 epochs: 25.5729\n",
      "loss avg after 9000 epochs: 25.9106\n",
      "loss avg after 10000 epochs: 14.4367\n",
      "-- repeat 4 of 5 --\n",
      "loss avg after 1000 epochs: 27.7028\n",
      "loss avg after 2000 epochs: 36.3136\n",
      "loss avg after 3000 epochs: 31.3708\n",
      "loss avg after 4000 epochs: 31.495\n",
      "loss avg after 5000 epochs: 26.4861\n",
      "loss avg after 6000 epochs: 38.2418\n",
      "loss avg after 7000 epochs: 29.9043\n",
      "loss avg after 8000 epochs: 34.1094\n",
      "loss avg after 9000 epochs: 27.1534\n",
      "loss avg after 10000 epochs: 26.7348\n",
      "-- repeat 5 of 5 --\n",
      "loss avg after 1000 epochs: 19.871\n",
      "loss avg after 2000 epochs: 22.8665\n",
      "loss avg after 3000 epochs: 17.8196\n",
      "loss avg after 4000 epochs: 17.2064\n",
      "loss avg after 5000 epochs: 17.4542\n",
      "loss avg after 6000 epochs: 17.1185\n",
      "loss avg after 7000 epochs: 15.8008\n",
      "loss avg after 8000 epochs: 11.872\n",
      "loss avg after 9000 epochs: 14.3059\n",
      "loss avg after 10000 epochs: 17.8634\n",
      "node_ins_recall: 0.640427 +- 0.0089452\n",
      "node_ins_precision: 1 +- 0\n",
      "node_del_recall: 0.96413 +- 0.0717391\n",
      "node_del_precision: 0.744229 +- 0.0452032\n",
      "edge_ins_recall: 0.963513 +- 0.0447239\n",
      "edge_ins_precision: 1 +- 0\n",
      "edge_del_recall: 1 +- 0\n",
      "edge_del_precision: 1 +- 0\n",
      "--- model GEN_crossent ---\n",
      "-- repeat 1 of 5 --\n",
      "loss avg after 1000 epochs: 0.0427338\n",
      "loss avg after 2000 epochs: 0.0234722\n",
      "loss avg after 3000 epochs: 0.0236033\n",
      "loss avg after 4000 epochs: 0.0277413\n",
      "loss avg after 5000 epochs: 0.0197227\n",
      "loss avg after 6000 epochs: 0.029103\n",
      "loss avg after 7000 epochs: 0.0265778\n",
      "loss avg after 8000 epochs: 0.0258953\n",
      "loss avg after 9000 epochs: 0.0329367\n",
      "loss avg after 10000 epochs: 0.0277045\n",
      "-- repeat 2 of 5 --\n",
      "loss avg after 1000 epochs: 0.0340596\n",
      "loss avg after 2000 epochs: 0.0467416\n",
      "loss avg after 3000 epochs: 0.0406296\n",
      "loss avg after 4000 epochs: 0.0274311\n",
      "loss avg after 5000 epochs: 0.0333922\n",
      "loss avg after 6000 epochs: 0.0350415\n",
      "loss avg after 7000 epochs: 0.027761\n",
      "loss avg after 8000 epochs: 0.0403381\n",
      "loss avg after 9000 epochs: 0.0264048\n",
      "loss avg after 10000 epochs: 0.0289339\n",
      "-- repeat 3 of 5 --\n",
      "loss avg after 1000 epochs: 0.0737358\n",
      "loss avg after 2000 epochs: 0.0288563\n",
      "loss avg after 3000 epochs: 0.0244533\n",
      "loss avg after 4000 epochs: 0.0272633\n",
      "loss avg after 5000 epochs: 0.032498\n",
      "loss avg after 6000 epochs: 0.0260526\n",
      "loss avg after 7000 epochs: 0.0316629\n",
      "loss avg after 8000 epochs: 0.0277157\n",
      "loss avg after 9000 epochs: 0.031931\n",
      "loss avg after 10000 epochs: 0.0326437\n",
      "-- repeat 4 of 5 --\n",
      "loss avg after 1000 epochs: 0.039793\n",
      "loss avg after 2000 epochs: 0.0347667\n",
      "loss avg after 3000 epochs: 0.0290309\n",
      "loss avg after 4000 epochs: 0.0398322\n",
      "loss avg after 5000 epochs: 0.024576\n",
      "loss avg after 6000 epochs: 0.0316206\n",
      "loss avg after 7000 epochs: 0.0245936\n",
      "loss avg after 8000 epochs: 0.0301063\n",
      "loss avg after 9000 epochs: 0.0346595\n",
      "loss avg after 10000 epochs: 0.0272661\n",
      "-- repeat 5 of 5 --\n",
      "loss avg after 1000 epochs: 0.029576\n",
      "loss avg after 2000 epochs: 0.0271762\n",
      "loss avg after 3000 epochs: 0.586093\n",
      "loss avg after 4000 epochs: 0.0293792\n",
      "loss avg after 5000 epochs: 0.0274133\n",
      "loss avg after 6000 epochs: 0.0254567\n",
      "loss avg after 7000 epochs: 0.0312239\n",
      "loss avg after 8000 epochs: 0.0348082\n",
      "loss avg after 9000 epochs: 0.032653\n",
      "loss avg after 10000 epochs: 0.0306693\n",
      "node_ins_recall: 1 +- 0\n",
      "node_ins_precision: 1 +- 0\n",
      "node_del_recall: 1 +- 0\n",
      "node_del_precision: 1 +- 0\n",
      "edge_ins_recall: 1 +- 0\n",
      "edge_ins_precision: 1 +- 0\n",
      "edge_del_recall: 1 +- 0\n",
      "edge_del_precision: 1 +- 0\n",
      "--- model GEN ---\n",
      "-- repeat 1 of 5 --\n",
      "-- repeat 2 of 5 --\n",
      "-- repeat 3 of 5 --\n",
      "loss avg after 1000 epochs: 0.0144871\n",
      "-- repeat 4 of 5 --\n",
      "-- repeat 5 of 5 --\n",
      "node_ins_recall: 1 +- 0\n",
      "node_ins_precision: 1 +- 0\n",
      "node_del_recall: 1 +- 0\n",
      "node_del_precision: 1 +- 0\n",
      "edge_ins_recall: 1 +- 0\n",
      "edge_ins_precision: 1 +- 0\n",
      "edge_del_recall: 1 +- 0\n",
      "edge_del_precision: 1 +- 0\n",
      "\n",
      "--- data set degree_rules_test100 ---\n",
      "\n",
      "--- model VGAE ---\n",
      "-- repeat 1 of 5 --\n",
      "loss avg after 1000 epochs: 407.483\n",
      "loss avg after 2000 epochs: 304.404\n",
      "loss avg after 3000 epochs: 230.565\n",
      "loss avg after 4000 epochs: 191.73\n",
      "loss avg after 5000 epochs: 196.585\n",
      "loss avg after 6000 epochs: 149.45\n",
      "loss avg after 7000 epochs: 112.367\n",
      "loss avg after 8000 epochs: 100.817\n",
      "loss avg after 9000 epochs: 89.5133\n",
      "loss avg after 10000 epochs: 91.9939\n",
      "-- repeat 2 of 5 --\n",
      "loss avg after 1000 epochs: 216.909\n",
      "loss avg after 2000 epochs: 164.4\n",
      "loss avg after 3000 epochs: 142.396\n",
      "loss avg after 4000 epochs: 111.024\n",
      "loss avg after 5000 epochs: 90.7518\n",
      "loss avg after 6000 epochs: 73.2676\n",
      "loss avg after 7000 epochs: 84.18\n",
      "loss avg after 8000 epochs: 66.068\n",
      "loss avg after 9000 epochs: 67.5478\n",
      "loss avg after 10000 epochs: 66.0943\n",
      "-- repeat 3 of 5 --\n",
      "loss avg after 1000 epochs: 366.37\n",
      "loss avg after 2000 epochs: 336.264\n",
      "loss avg after 3000 epochs: 316.255\n",
      "loss avg after 4000 epochs: 303.308\n",
      "loss avg after 5000 epochs: 222.846\n",
      "loss avg after 6000 epochs: 220.807\n",
      "loss avg after 7000 epochs: 226.629\n",
      "loss avg after 8000 epochs: 174.351\n",
      "loss avg after 9000 epochs: 225.311\n",
      "loss avg after 10000 epochs: 180.96\n",
      "-- repeat 4 of 5 --\n",
      "loss avg after 1000 epochs: 477.23\n",
      "loss avg after 2000 epochs: 371.313\n",
      "loss avg after 3000 epochs: 412.881\n",
      "loss avg after 4000 epochs: 327.725\n",
      "loss avg after 5000 epochs: 304.818\n",
      "loss avg after 6000 epochs: 300.87\n",
      "loss avg after 7000 epochs: 299.971\n",
      "loss avg after 8000 epochs: 291.986\n",
      "loss avg after 9000 epochs: 230.148\n",
      "loss avg after 10000 epochs: 238.712\n",
      "-- repeat 5 of 5 --\n",
      "loss avg after 1000 epochs: 290.519\n",
      "loss avg after 2000 epochs: 221.875\n",
      "loss avg after 3000 epochs: 174.45\n",
      "loss avg after 4000 epochs: 151.348\n",
      "loss avg after 5000 epochs: 113.14\n",
      "loss avg after 6000 epochs: 103.353\n",
      "loss avg after 7000 epochs: 84.6146\n",
      "loss avg after 8000 epochs: 86.527\n",
      "loss avg after 9000 epochs: 77.8335\n",
      "loss avg after 10000 epochs: 64.641\n",
      "node_ins_recall: 0.131112 +- 0.00807872\n",
      "node_ins_precision: 1 +- 0\n",
      "node_del_recall: 0.990428 +- 0.00574368\n",
      "node_del_precision: 0.925124 +- 0.0409349\n",
      "edge_ins_recall: 0.835711 +- 0.0687809\n",
      "edge_ins_precision: 0.854661 +- 0.155212\n",
      "edge_del_recall: 1 +- 0\n",
      "edge_del_precision: 0.848273 +- 0.173499\n",
      "--- model GEN_crossent ---\n",
      "-- repeat 1 of 5 --\n",
      "loss avg after 1000 epochs: 15.2567\n",
      "loss avg after 2000 epochs: 13.6069\n",
      "loss avg after 3000 epochs: 9.89346\n",
      "loss avg after 4000 epochs: 9.26968\n",
      "loss avg after 5000 epochs: 7.8657\n",
      "loss avg after 6000 epochs: 6.77338\n",
      "loss avg after 7000 epochs: 6.446\n",
      "loss avg after 8000 epochs: 6.20131\n",
      "loss avg after 9000 epochs: 6.07658\n",
      "loss avg after 10000 epochs: 6.08968\n",
      "-- repeat 2 of 5 --\n",
      "loss avg after 1000 epochs: 13.3826\n",
      "loss avg after 2000 epochs: 10.7566\n",
      "loss avg after 3000 epochs: 8.10889\n",
      "loss avg after 4000 epochs: 8.9647\n",
      "loss avg after 5000 epochs: 1.75494\n",
      "loss avg after 6000 epochs: 2.23293\n",
      "loss avg after 7000 epochs: 1.48895\n",
      "loss avg after 8000 epochs: 0.728981\n",
      "loss avg after 9000 epochs: 0.937818\n",
      "loss avg after 10000 epochs: 0.559948\n",
      "-- repeat 3 of 5 --\n",
      "loss avg after 1000 epochs: 12.2513\n",
      "loss avg after 2000 epochs: 10.1232\n",
      "loss avg after 3000 epochs: 8.77299\n",
      "loss avg after 4000 epochs: 7.99338\n",
      "loss avg after 5000 epochs: 7.98703\n",
      "loss avg after 6000 epochs: 8.21964\n",
      "loss avg after 7000 epochs: 6.13575\n",
      "loss avg after 8000 epochs: 6.1043\n",
      "loss avg after 9000 epochs: 5.12265\n",
      "loss avg after 10000 epochs: 6.76901\n",
      "-- repeat 4 of 5 --\n",
      "loss avg after 1000 epochs: 13.0725\n",
      "loss avg after 2000 epochs: 9.68123\n",
      "loss avg after 3000 epochs: 9.06016\n",
      "loss avg after 4000 epochs: 8.94474\n",
      "loss avg after 5000 epochs: 9.26971\n",
      "loss avg after 6000 epochs: 8.27861\n",
      "loss avg after 7000 epochs: 6.29173\n",
      "loss avg after 8000 epochs: 3.49198\n",
      "loss avg after 9000 epochs: 1.02147\n",
      "loss avg after 10000 epochs: 0.804213\n",
      "-- repeat 5 of 5 --\n",
      "loss avg after 1000 epochs: 17.3432\n",
      "loss avg after 2000 epochs: 11.2964\n",
      "loss avg after 3000 epochs: 8.93626\n",
      "loss avg after 4000 epochs: 6.88845\n",
      "loss avg after 5000 epochs: 6.34433\n",
      "loss avg after 6000 epochs: 5.452\n",
      "loss avg after 7000 epochs: 4.70378\n",
      "loss avg after 8000 epochs: 4.16283\n",
      "loss avg after 9000 epochs: 3.88352\n",
      "loss avg after 10000 epochs: 5.49725\n",
      "node_ins_recall: 0.999914 +- 0.000105814\n",
      "node_ins_precision: 0.999094 +- 0.00108228\n",
      "node_del_recall: 0.999906 +- 0.000188679\n",
      "node_del_precision: 0.999373 +- 0.00113423\n",
      "edge_ins_recall: 0.905563 +- 0.0822205\n",
      "edge_ins_precision: 0.969919 +- 0.0181966\n",
      "edge_del_recall: 1 +- 0\n",
      "edge_del_precision: 0.990602 +- 0.00591947\n",
      "--- model GEN ---\n",
      "-- repeat 1 of 5 --\n",
      "loss avg after 1000 epochs: 46.2939\n",
      "loss avg after 2000 epochs: 37.7788\n",
      "loss avg after 3000 epochs: 32.3396\n",
      "loss avg after 4000 epochs: 32.5849\n",
      "loss avg after 5000 epochs: 28.2951\n",
      "loss avg after 6000 epochs: 27.0442\n",
      "loss avg after 7000 epochs: 28.3391\n",
      "loss avg after 8000 epochs: 25.5095\n",
      "loss avg after 9000 epochs: 25.7863\n",
      "loss avg after 10000 epochs: 21.4561\n",
      "-- repeat 2 of 5 --\n",
      "loss avg after 1000 epochs: 4.35949\n",
      "loss avg after 2000 epochs: 2.15076\n",
      "loss avg after 3000 epochs: 0.989364\n",
      "loss avg after 4000 epochs: 0.97678\n",
      "loss avg after 5000 epochs: 3.64186\n",
      "loss avg after 6000 epochs: 0.164091\n",
      "loss avg after 7000 epochs: 0.420439\n",
      "loss avg after 8000 epochs: 0.798511\n",
      "loss avg after 9000 epochs: 0.333278\n",
      "loss avg after 10000 epochs: 0.354378\n",
      "-- repeat 3 of 5 --\n",
      "loss avg after 1000 epochs: 7.69371\n",
      "loss avg after 2000 epochs: 4.29445\n",
      "loss avg after 3000 epochs: 5.77754\n",
      "loss avg after 4000 epochs: 2.27758\n",
      "loss avg after 5000 epochs: 0.65581\n",
      "loss avg after 6000 epochs: 1.20195\n",
      "loss avg after 7000 epochs: 3.8388\n",
      "loss avg after 8000 epochs: 1.31051\n",
      "loss avg after 9000 epochs: 1.03226\n",
      "loss avg after 10000 epochs: 1.34169\n",
      "-- repeat 4 of 5 --\n",
      "loss avg after 1000 epochs: 49.071\n",
      "loss avg after 2000 epochs: 37.4782\n",
      "loss avg after 3000 epochs: 26.5788\n",
      "loss avg after 4000 epochs: 30.0218\n",
      "loss avg after 5000 epochs: 24.0335\n",
      "loss avg after 6000 epochs: 21.8932\n",
      "loss avg after 7000 epochs: 21.7351\n",
      "loss avg after 8000 epochs: 19.7559\n",
      "loss avg after 9000 epochs: 20.948\n",
      "loss avg after 10000 epochs: 22.3001\n",
      "-- repeat 5 of 5 --\n",
      "loss avg after 1000 epochs: 10.1973\n",
      "loss avg after 2000 epochs: 4.32468\n",
      "loss avg after 3000 epochs: 2.55558\n",
      "loss avg after 4000 epochs: 1.30347\n",
      "loss avg after 5000 epochs: 3.00146\n",
      "loss avg after 6000 epochs: 0.620724\n",
      "loss avg after 7000 epochs: 0.351988\n",
      "loss avg after 8000 epochs: 0.570735\n",
      "loss avg after 9000 epochs: 0.52696\n",
      "loss avg after 10000 epochs: 0.243236\n",
      "node_ins_recall: 0.999822 +- 0.000317466\n",
      "node_ins_precision: 0.997579 +- 0.00471488\n",
      "node_del_recall: 1 +- 0\n",
      "node_del_precision: 0.995943 +- 0.00538136\n",
      "edge_ins_recall: 0.891646 +- 0.138224\n",
      "edge_ins_precision: 0.981655 +- 0.0231839\n",
      "edge_del_recall: 1 +- 0\n",
      "edge_del_precision: 0.989806 +- 0.0132954\n",
      "\n",
      "--- data set game_of_life_test100 ---\n",
      "\n",
      "--- model VGAE ---\n",
      "node_ins_recall: 0.2378 +- 0.0443775\n",
      "node_ins_precision: 1 +- 0\n",
      "node_del_recall: 1 +- 0\n",
      "node_del_precision: 0.0373376 +- 0.00177806\n",
      "edge_ins_recall: 1 +- 0\n",
      "edge_ins_precision: 0.978 +- 0.044\n",
      "edge_del_recall: 1 +- 0\n",
      "edge_del_precision: 0.9924 +- 0.0152\n",
      "--- model GEN_crossent ---\n",
      "node_ins_recall: 0.427353 +- 0.288787\n",
      "node_ins_precision: 0.9971 +- 0.0058\n",
      "node_del_recall: 0.55754 +- 0.292743\n",
      "node_del_precision: 1 +- 0\n",
      "edge_ins_recall: 1 +- 0\n",
      "edge_ins_precision: 1 +- 0\n",
      "edge_del_recall: 1 +- 0\n",
      "edge_del_precision: 1 +- 0\n",
      "--- model GEN ---\n",
      "-- repeat 4 of 5 --\n",
      "loss avg after 1000 epochs: 95.8404\n",
      "loss avg after 2000 epochs: 68.5788\n",
      "loss avg after 3000 epochs: 47.8998\n",
      "loss avg after 4000 epochs: 31.8968\n",
      "loss avg after 5000 epochs: 23.6273\n",
      "loss avg after 6000 epochs: 14.8714\n",
      "loss avg after 7000 epochs: 34.2512\n",
      "loss avg after 8000 epochs: 6.80053\n",
      "loss avg after 9000 epochs: 82.7725\n",
      "loss avg after 10000 epochs: 63.7517\n",
      "-- repeat 5 of 5 --\n",
      "loss avg after 1000 epochs: 700.502\n",
      "loss avg after 2000 epochs: 290.68\n",
      "loss avg after 3000 epochs: 284.855\n",
      "loss avg after 4000 epochs: 210.118\n",
      "loss avg after 5000 epochs: 170.628\n",
      "loss avg after 6000 epochs: 75.5134\n",
      "loss avg after 7000 epochs: 48.5484\n",
      "loss avg after 8000 epochs: 34.4963\n",
      "loss avg after 9000 epochs: 29.9419\n",
      "loss avg after 10000 epochs: 38.1457\n",
      "node_ins_recall: 0.2316 +- 0.0313088\n",
      "node_ins_precision: 1 +- 0\n",
      "node_del_recall: 0.358232 +- 0.197366\n",
      "node_del_precision: 0.973886 +- 0.0354899\n",
      "edge_ins_recall: 1 +- 0\n",
      "edge_ins_precision: 0.999 +- 0.00126491\n",
      "edge_del_recall: 1 +- 0\n",
      "edge_del_precision: 1 +- 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "# iterate over all datasets\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(eval_criteria, columns = ['eval'])\n",
    "for d in range(len(datasets)):\n",
    "    print('\\n--- data set %s ---\\n' % datasets[d])\n",
    "    # load partial runtime results if possible\n",
    "    runtimes_file = 'results/%s_runtimes.csv' % datasets[d]\n",
    "    if os.path.exists(runtimes_file):\n",
    "        runtimes = np.loadtxt(runtimes_file, skiprows = 1, delimiter = '\\t')\n",
    "    else:\n",
    "        runtimes = np.full((R, len(models)), np.nan)\n",
    "    # iterate over all models\n",
    "    for k in range(len(models)):\n",
    "        print('--- model %s ---' % models[k])\n",
    "        # load partial results if possible\n",
    "        results_file = 'results/%s_%s_results.csv' % (datasets[d], models[k])\n",
    "        curves_file  = 'results/%s_%s_learning_curves.csv' % (datasets[d], models[k])\n",
    "        if os.path.exists(results_file):\n",
    "            results = np.loadtxt(results_file, skiprows = 1, delimiter = '\\t')\n",
    "            learning_curves = np.loadtxt(curves_file, delimiter = '\\t')\n",
    "        else:\n",
    "            results = np.full((R, len(eval_criteria)), np.nan)\n",
    "            learning_curves = np.full((max_epochs, R), np.nan)\n",
    "        # iterate over experimental repeats\n",
    "        for r in range(R):\n",
    "            # check if this repeat is already evaluated; if so, skip it\n",
    "            if not np.isnan(learning_curves[0, r]):\n",
    "                continue\n",
    "            print('-- repeat %d of %d --' % (r+1, R))\n",
    "            start_time = time.time()\n",
    "            # set up model\n",
    "            if datasets[d] == 'game_of_life':\n",
    "                nonlin = torch.nn.Sigmoid()\n",
    "            else:\n",
    "                nonlin = torch.nn.ReLU()\n",
    "            model = setup_funs[k](dim_ins[d], nonlin)\n",
    "            # set up optimizer\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "            # initialize moving loss average for printing\n",
    "            loss_avg = None\n",
    "            # start training\n",
    "            for epoch in range(max_epochs):\n",
    "                optimizer.zero_grad()\n",
    "                # sample a time series from the data set\n",
    "                As, Xs, deltas, Epsilons = generator_funs[d]()\n",
    "                # compute the loss over all time steps\n",
    "                loss = 0.\n",
    "                for t in range(len(As)):\n",
    "                    # compute loss\n",
    "                    loss_obj = loss_funs[k](model, As[t], Xs[t], deltas[t], Epsilons[t])\n",
    "                    # compute gradient\n",
    "                    loss_obj.backward()\n",
    "                    # accumulate loss\n",
    "                    loss += loss_obj.item()\n",
    "                # perform an optimizer step\n",
    "                optimizer.step()\n",
    "                # store the current loss value in the learning curve\n",
    "                learning_curves[epoch, r] = loss\n",
    "                # compute a new moving average over the loss\n",
    "                if loss_avg is None:\n",
    "                    loss_avg = loss\n",
    "                else:\n",
    "                    loss_avg = loss_avg * 0.9 + 0.1 * loss\n",
    "                # print every print_step steps\n",
    "                if(epoch+1) % print_step == 0:\n",
    "                    print('loss avg after %d epochs: %g' % (epoch+1, loss_avg))\n",
    "                # stop early if the moving average is small\n",
    "                if loss_avg < loss_threshold:\n",
    "                    break\n",
    "            # perform evaluation on new time series\n",
    "            results[r, :] = 0.\n",
    "            T = 0\n",
    "            for j in range(N_test):\n",
    "                # get a random time series from the dataset\n",
    "                As, Xs, deltas, Epsilons = generator_funs[d]()\n",
    "                for t in range(len(As)):\n",
    "                    # predict the current time step with the network\n",
    "                    delta, Epsilon = pred_funs[k](model, As[t], Xs[t])\n",
    "                    # assess node edit precision and recall\n",
    "                    results[r, :4] += prec_rec(delta, deltas[t])\n",
    "                    # assess edge edit precision and recall\n",
    "                    results[r, 4:] += prec_rec(Epsilon, Epsilons[t])\n",
    "                        \n",
    "                T += len(As)\n",
    "            results[r, :] /= T\n",
    "            # store runtime\n",
    "            runtimes[r, k] = time.time() - start_time\n",
    "            np.savetxt(runtimes_file, runtimes, delimiter = '\\t', fmt = '%g', header = '\\t'.join(models), comments = '')\n",
    "            # store results\n",
    "            np.savetxt(results_file, results, delimiter = '\\t', fmt = '%g', header = '\\t'.join(eval_criteria), comments = '')\n",
    "            # store learning curves\n",
    "            np.savetxt(curves_file, learning_curves, delimiter = '\\t', fmt = '%g')\n",
    "        # print results\n",
    "        res_collect = []\n",
    "        for crit in range(len(eval_criteria)):\n",
    "            res_collect.append('%g +- %g' % ( np.mean(results[:, crit]), np.std(results[:, crit])))\n",
    "            print('%s: %g +- %g' % (eval_criteria[crit], np.mean(results[:, crit]), np.std(results[:, crit])))\n",
    "        df[str(datasets[d]) + \"_\" + str(models[k])] = res_collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval</th>\n",
       "      <th>degree_rules_VGAE</th>\n",
       "      <th>degree_rules_GEN_crossent</th>\n",
       "      <th>degree_rules_GEN</th>\n",
       "      <th>degree_rules_erdos_VGAE</th>\n",
       "      <th>degree_rules_erdos_GEN_crossent</th>\n",
       "      <th>degree_rules_erdos_GEN</th>\n",
       "      <th>degree_rules_conf_VGAE</th>\n",
       "      <th>degree_rules_conf_GEN_crossent</th>\n",
       "      <th>degree_rules_conf_GEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>node_ins_recall</td>\n",
       "      <td>0.132317 +- 0.0161696</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>0.135857 +- 0.0374516</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>0.109958 +- 0.00377312</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>node_ins_precision</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>0.998291 +- 0.0034188</td>\n",
       "      <td>0.996146 +- 0.00724875</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>0.99964 +- 0.0007208</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>0.996809 +- 0.0063828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>node_del_recall</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>0.999365 +- 0.00127</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>0.929696 +- 0.0473053</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>node_del_precision</td>\n",
       "      <td>0.963691 +- 0.0181389</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>0.999688 +- 0.0006232</td>\n",
       "      <td>0.945331 +- 0.0232628</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>0.876126 +- 0.0329103</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>edge_ins_recall</td>\n",
       "      <td>0.874061 +- 0.0298417</td>\n",
       "      <td>0.983814 +- 0.0323716</td>\n",
       "      <td>0.961416 +- 0.0473139</td>\n",
       "      <td>0.841111 +- 0.0303961</td>\n",
       "      <td>0.967787 +- 0.0319892</td>\n",
       "      <td>0.923691 +- 0.101971</td>\n",
       "      <td>0.902128 +- 0.0515282</td>\n",
       "      <td>0.973148 +- 0.0514269</td>\n",
       "      <td>0.919352 +- 0.109697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>edge_ins_precision</td>\n",
       "      <td>0.936107 +- 0.0783303</td>\n",
       "      <td>0.993129 +- 0.0133892</td>\n",
       "      <td>0.97117 +- 0.036894</td>\n",
       "      <td>0.772609 +- 0.117451</td>\n",
       "      <td>0.98148 +- 0.0168492</td>\n",
       "      <td>0.982949 +- 0.0210265</td>\n",
       "      <td>0.87897 +- 0.144188</td>\n",
       "      <td>0.987234 +- 0.0171623</td>\n",
       "      <td>0.991116 +- 0.0131835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>edge_del_recall</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>edge_del_precision</td>\n",
       "      <td>0.929203 +- 0.0877218</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>0.84197 +- 0.100397</td>\n",
       "      <td>1 +- 0</td>\n",
       "      <td>0.988293 +- 0.0112543</td>\n",
       "      <td>0.502145 +- 0.119931</td>\n",
       "      <td>0.998131 +- 0.0037384</td>\n",
       "      <td>0.9848 +- 0.0206911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 eval      degree_rules_VGAE degree_rules_GEN_crossent  \\\n",
       "0     node_ins_recall  0.132317 +- 0.0161696                    1 +- 0   \n",
       "1  node_ins_precision                 1 +- 0     0.998291 +- 0.0034188   \n",
       "2     node_del_recall                 1 +- 0                    1 +- 0   \n",
       "3  node_del_precision  0.963691 +- 0.0181389                    1 +- 0   \n",
       "4     edge_ins_recall  0.874061 +- 0.0298417     0.983814 +- 0.0323716   \n",
       "5  edge_ins_precision  0.936107 +- 0.0783303     0.993129 +- 0.0133892   \n",
       "6     edge_del_recall                 1 +- 0                    1 +- 0   \n",
       "7  edge_del_precision  0.929203 +- 0.0877218                    1 +- 0   \n",
       "\n",
       "         degree_rules_GEN degree_rules_erdos_VGAE  \\\n",
       "0                  1 +- 0   0.135857 +- 0.0374516   \n",
       "1  0.996146 +- 0.00724875                  1 +- 0   \n",
       "2                  1 +- 0     0.999365 +- 0.00127   \n",
       "3   0.999688 +- 0.0006232   0.945331 +- 0.0232628   \n",
       "4   0.961416 +- 0.0473139   0.841111 +- 0.0303961   \n",
       "5     0.97117 +- 0.036894    0.772609 +- 0.117451   \n",
       "6                  1 +- 0                  1 +- 0   \n",
       "7                  1 +- 0     0.84197 +- 0.100397   \n",
       "\n",
       "  degree_rules_erdos_GEN_crossent degree_rules_erdos_GEN  \\\n",
       "0                          1 +- 0                 1 +- 0   \n",
       "1                          1 +- 0   0.99964 +- 0.0007208   \n",
       "2                          1 +- 0                 1 +- 0   \n",
       "3                          1 +- 0                 1 +- 0   \n",
       "4           0.967787 +- 0.0319892   0.923691 +- 0.101971   \n",
       "5            0.98148 +- 0.0168492  0.982949 +- 0.0210265   \n",
       "6                          1 +- 0                 1 +- 0   \n",
       "7                          1 +- 0  0.988293 +- 0.0112543   \n",
       "\n",
       "   degree_rules_conf_VGAE degree_rules_conf_GEN_crossent  \\\n",
       "0  0.109958 +- 0.00377312                         1 +- 0   \n",
       "1                  1 +- 0                         1 +- 0   \n",
       "2   0.929696 +- 0.0473053                         1 +- 0   \n",
       "3   0.876126 +- 0.0329103                         1 +- 0   \n",
       "4   0.902128 +- 0.0515282          0.973148 +- 0.0514269   \n",
       "5     0.87897 +- 0.144188          0.987234 +- 0.0171623   \n",
       "6                  1 +- 0                         1 +- 0   \n",
       "7    0.502145 +- 0.119931          0.998131 +- 0.0037384   \n",
       "\n",
       "   degree_rules_conf_GEN  \n",
       "0                 1 +- 0  \n",
       "1  0.996809 +- 0.0063828  \n",
       "2                 1 +- 0  \n",
       "3                 1 +- 0  \n",
       "4   0.919352 +- 0.109697  \n",
       "5  0.991116 +- 0.0131835  \n",
       "6                 1 +- 0  \n",
       "7    0.9848 +- 0.0206911  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize learning curves\n",
    "import matplotlib.pyplot as plt\n",
    "smoothing_steps = 10\n",
    "fig, axes = plt.subplots(ncols=1, nrows=len(datasets))\n",
    "for d in range(len(datasets)):\n",
    "    for k in range(len(models)):\n",
    "        curves_file  = 'results/%s_%s_learning_curves.csv' % (datasets[d], models[k])\n",
    "        learning_curves = np.loadtxt(curves_file, delimiter = '\\t')\n",
    "        acum = np.cumsum(np.nanmean(learning_curves, 1))\n",
    "        axes[d].semilogy((acum[smoothing_steps:] - acum[:-smoothing_steps])/smoothing_steps)\n",
    "    axes[d].set_xlabel('epoch')\n",
    "    axes[d].set_ylabel('loss')\n",
    "    axes[d].set_title(datasets[d])\n",
    "    axes[d].legend(models)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
